{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9037572",
   "metadata": {},
   "source": [
    "# Summary of time taken and brier scores for jaxlogit, xlogit, and biogeme\n",
    "Where the estimation is using draws = 600 (suboptimal but highest without running out of memory in biogeme), and training and test data is separated.\n",
    "\n",
    "| | jaxlogit | xlogit | biogeme |\n",
    "|---|---|---|---|\n",
    "|Making Model | 37.7s | 16.9s | 4:15 |\n",
    "|Estimating | 1.6s | 0.0s | 15.4s |\n",
    "|Brier Score | 0.6345 | 0.6345 | 0.6345 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2ad5e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a05d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/evelyn/projects_shared/jaxlogit\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import pathlib\n",
    "import xlogit\n",
    "import sklearn\n",
    "\n",
    "from jaxlogit.mixed_logit import MixedLogit, ConfigData\n",
    "from jaxlogit.utils import wide_to_long\n",
    "\n",
    "import biogeme.biogeme_logging as blog\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Draws, log, MonteCarlo, PanelLikelihoodTrajectory\n",
    "import biogeme.database as db\n",
    "from biogeme.expressions import Variable\n",
    "\n",
    "logger = blog.get_screen_logger()\n",
    "logger.setLevel(blog.INFO)\n",
    "\n",
    "#  64bit precision\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "os.chdir(\"/home/evelyn/projects_shared/jaxlogit/examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49263ce0",
   "metadata": {},
   "source": [
    "# Get the full electricity dataset\n",
    "\n",
    "Use for jaxlogit and xlogit. Adjustusting n_draws can improve accuracy, but Biogeme cannot handle 700 or more draws with this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fa6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pathlib.Path.cwd() / \"electricity_long.csv\")\n",
    "varnames = ['pf', 'cl', 'loc', 'wk', 'tod', 'seas']\n",
    "n_draws = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3776c3",
   "metadata": {},
   "source": [
    "Reshape the data so it can be passed to test_train_split in a wide format. Additionally, xlogit and jaxlogit require long format while biogeme requires a wide format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.read_csv(pathlib.Path.cwd() / \"electricity_long.csv\")\n",
    "choice_df = df_long.loc[df_long['choice'] == 1, ['id', 'chid', 'alt']]\n",
    "choice_df = choice_df.rename(columns={'alt': 'choice'})\n",
    "df_wide = df_long.pivot(index=['id', 'chid'], columns='alt', values=varnames)\n",
    "df_wide.columns = [f'{var}_{alt}' for var, alt in df_wide.columns]\n",
    "df_wide = df_wide.reset_index()\n",
    "df = df_wide.merge(\n",
    "    choice_df,\n",
    "    on=['id', 'chid'],\n",
    "    how='inner',\n",
    "    validate='one_to_one'\n",
    ")\n",
    "\n",
    "df_wide_train, df_wide_test = sklearn.model_selection.train_test_split(df, train_size=0.2)\n",
    "df_train = wide_to_long(df_wide_train, \"chid\", [1,2,3,4], \"alt\", varying=varnames, panels=True)\n",
    "df_train = df_train.sort_values(['chid', 'alt'])\n",
    "df_test = wide_to_long(df_wide_test, \"chid\", [1,2,3,4], \"alt\", varying=varnames, panels=True)\n",
    "df_test = df_test.sort_values(['chid', 'alt'])\n",
    "\n",
    "df_wide_train = df_wide_train.sort_values('chid')\n",
    "database_train = db.Database('electricity', df_wide_train)\n",
    "database_train.panel('id')\n",
    "database_test = db.Database('electricity', df_wide_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ed5fe",
   "metadata": {},
   "source": [
    "jaxlogit and xlogit setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46257705",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[varnames]\n",
    "y_train = df_train['choice']\n",
    "\n",
    "ids_train = df_train['chid']\n",
    "alts_train = df_train['alt']\n",
    "panels_train = df_train['id']\n",
    "\n",
    "X_test = df_test[varnames]\n",
    "y_test = df_test['choice']\n",
    "\n",
    "ids_test = df_test['chid']\n",
    "alts_test = df_test['alt']\n",
    "panels_test = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535c39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "randvars = {'pf': 'n', 'cl': 'n', 'loc': 'n', 'wk': 'n', 'tod': 'n', 'seas': 'n'}\n",
    "\n",
    "model_jax = MixedLogit()\n",
    "model_x = xlogit.MixedLogit()\n",
    "\n",
    "config = ConfigData(\n",
    "    panels=panels_train,\n",
    "    n_draws=n_draws,\n",
    "    skip_std_errs=True,  # skip standard errors to speed up the example\n",
    "    batch_size=None,\n",
    "    optim_method=\"BFGS\",\n",
    ")\n",
    "init_coeff = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd8b9a",
   "metadata": {},
   "source": [
    "Biogeme setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b58c4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {\n",
    "    name: {\n",
    "        j: Variable(f\"{name}_{j}\")\n",
    "        for j in [1,2,3,4]\n",
    "    }\n",
    "    for name in varnames\n",
    "}\n",
    "\n",
    "alt_1 = Beta('alt_1', 0, None, None, 0)\n",
    "alt_2 = Beta('alt_2', 0, None, None, 0)\n",
    "alt_3 = Beta('alt_3', 0, None, None, 0)\n",
    "alt_4 = Beta('alt_4', 0, None, None, 1)\n",
    "\n",
    "pf_mean = Beta('pf_mean', 0, None, None, 0)\n",
    "pf_sd = Beta('pf_sd', 1, None, None, 0)\n",
    "cl_mean = Beta('cl_mean', 0, None, None, 0)\n",
    "cl_sd = Beta('cl_sd', 1, None, None, 0)\n",
    "loc_mean = Beta('loc_mean', 0, None, None, 0)\n",
    "loc_sd = Beta('loc_sd', 1, None, None, 0)\n",
    "wk_mean = Beta('wk_mean', 0, None, None, 0)\n",
    "wk_sd = Beta('wk_sd', 1, None, None, 0)\n",
    "tod_mean = Beta('tod_mean', 0, None, None, 0)\n",
    "tod_sd = Beta('tod_sd', 1, None, None, 0)\n",
    "seas_mean = Beta('seas_mean', 0, None, None, 0)\n",
    "seas_sd = Beta('seas_sd', 1, None, None, 0)\n",
    "\n",
    "pf_rnd = pf_mean + pf_sd * Draws('pf_rnd', 'NORMAL')\n",
    "cl_rnd = cl_mean + cl_sd * Draws('cl_rnd', 'NORMAL')\n",
    "loc_rnd = loc_mean + loc_sd * Draws('loc_rnd', 'NORMAL')\n",
    "wk_rnd = wk_mean + wk_sd * Draws('wk_rnd', 'NORMAL')\n",
    "tod_rnd = tod_mean + tod_sd * Draws('tod_rnd', 'NORMAL')\n",
    "seas_rnd = seas_mean + seas_sd * Draws('seas_rnd', 'NORMAL')\n",
    "\n",
    "choice = Variable('choice')\n",
    "\n",
    "V = {\n",
    "    j: pf_rnd * X['pf'][j] + cl_rnd * X['cl'][j] + loc_rnd * X['loc'][j] + wk_rnd * X['wk'][j] + tod_rnd * X['tod'][j] + seas_rnd * X['seas'][j]\n",
    "    for j in [1,2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8c388",
   "metadata": {},
   "source": [
    "# Make the models\n",
    "Jaxlogit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c1ceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown optimization method: L-BFGS-optax exiting gracefully\n",
      "Optimization failed, returning None.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_jax_lbfgs = MixedLogit()\n",
    "config = ConfigData(\n",
    "    panels=panels_train,\n",
    "    n_draws=n_draws,\n",
    "    skip_std_errs=True,  # skip standard errors to speed up the example\n",
    "    batch_size=None,\n",
    "    optim_method=\"L-BFGS-optax\",\n",
    "    maxiter=200,\n",
    ")\n",
    "model_jax_lbfgs.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    varnames=varnames,\n",
    "    ids=ids_train,\n",
    "    alts=alts_train,\n",
    "    randvars=randvars,\n",
    "    config=config\n",
    ")\n",
    "display(model_jax_lbfgs.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52742f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown optimization method: L-BFGS-optax exiting gracefully\n",
      "Optimization failed, returning None.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_jax_bfgs = MixedLogit()\n",
    "config = ConfigData(\n",
    "    panels=panels_train,\n",
    "    n_draws=n_draws,\n",
    "    skip_std_errs=True,  # skip standard errors to speed up the example\n",
    "    batch_size=None,\n",
    "    optim_method=\"L-BFGS-optax\",\n",
    "    maxiter=100,\n",
    ")\n",
    "\n",
    "model_jax_bfgs.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    varnames=varnames,\n",
    "    ids=ids_train,\n",
    "    alts=alts_train,\n",
    "    randvars=randvars,\n",
    "    config=config\n",
    ")\n",
    "display(model_jax_bfgs.summary())\n",
    "init_coeff_j = model_jax.coeff_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53d9f8",
   "metadata": {},
   "source": [
    "xlogit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89a636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "    Message: CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH\n",
      "    Iterations: 80\n",
      "    Function evaluations: 89\n",
      "Estimation time= 8.0 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Coefficient              Estimate      Std.Err.         z-val         P>|z|\n",
      "---------------------------------------------------------------------------\n",
      "pf                     -0.8360834     1.0000000    -0.8360834         0.403    \n",
      "cl                     -0.1794560     1.0000000    -0.1794560         0.858    \n",
      "loc                     1.8255459     1.0000000     1.8255459        0.0683 .  \n",
      "wk                      1.2644040     1.0000000     1.2644040         0.206    \n",
      "tod                    -8.0431821     1.0000000    -8.0431821      2.89e-15 ***\n",
      "seas                   -8.5806229     1.0000000    -8.5806229      4.36e-17 ***\n",
      "sd.pf                   0.1636602     1.0000000     0.1636602          0.87    \n",
      "sd.cl                   0.3866868     1.0000000     0.3866868         0.699    \n",
      "sd.loc                  1.0720259     1.0000000     1.0720259         0.284    \n",
      "sd.wk                   0.4593844     1.0000000     0.4593844         0.646    \n",
      "sd.tod                  2.0065305     1.0000000     2.0065305        0.0451 *  \n",
      "sd.seas                 1.5830641     1.0000000     1.5830641         0.114    \n",
      "---------------------------------------------------------------------------\n",
      "Significance:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "Log-Likelihood= -933.834\n",
      "AIC= 1891.669\n",
      "BIC= 1948.766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_x.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    varnames=varnames,\n",
    "    ids=ids_train,\n",
    "    alts=alts_train,\n",
    "    randvars=randvars,\n",
    "    panels=panels_train,\n",
    "    n_draws=n_draws,\n",
    "    skip_std_errs=True,  # skip standard errors to speed up the example\n",
    "    batch_size=None,\n",
    "    optim_method=\"L-BFGS-B\",\n",
    ")\n",
    "display(model_x.summary())\n",
    "init_coeff_x = model_x.coeff_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2add0a",
   "metadata": {},
   "source": [
    "Biogeme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fe20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The number of draws (600) is low. The results may not be meaningful. \n",
      "The number of draws (600) is low. The results may not be meaningful. \n",
      "The number of draws (600) is low. The results may not be meaningful. \n"
     ]
    }
   ],
   "source": [
    "prob = models.logit(V, None, choice)\n",
    "logprob = log(MonteCarlo(PanelLikelihoodTrajectory(prob)))\n",
    "\n",
    "the_biogeme = bio.BIOGEME(\n",
    "    database_train, logprob, number_of_draws=n_draws, seed=999, generate_yaml=False, generate_html=False\n",
    ")\n",
    "the_biogeme.model_name = 'model_b'\n",
    "results = the_biogeme.estimate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486e8e2",
   "metadata": {},
   "source": [
    "# Compare parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1a3992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m fmt = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:13}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{:13.7f}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{:13.7f}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{:13.7f}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m coeff_names = {\u001b[33m'\u001b[39m\u001b[33mpf\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpf_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msd.pf\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpf_sd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcl\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcl_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msd.cl\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcl_sd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mloc\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mloc_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msd.loc\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mloc_sd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwk\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mwk_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msd.wk\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mwk_sd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtod\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mtod_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msd.tod\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mtod_sd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mseas\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mseas_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msd.seas\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mseas_sd\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_jax_bfgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoeff_\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m      6\u001b[39m     name = model_jax_bfgs.coeff_names[i]\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(fmt.format(name[:\u001b[32m13\u001b[39m], \n\u001b[32m      8\u001b[39m                      model_jax_bfgs.coeff_[i], \n\u001b[32m      9\u001b[39m                      model_jax_lbfgs.coeff_[i], \n\u001b[32m     10\u001b[39m                      model_x.coeff_[i]))\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# print(\"{:>13} {:>13} {:>13} {:>13}\".format(\"Estimate\", \"Jaxlogit_BFGS\", \"Jaxlogit_L-BFGS\", \"xlogit\"))\n",
    "print(\"-\" * 58)\n",
    "fmt = \"{:13} {:13.7f} {:13.7f} {:13.7f}\"\n",
    "coeff_names = {'pf': 'pf_mean', 'sd.pf': 'pf_sd', 'cl': 'cl_mean', 'sd.cl': 'cl_sd', 'loc': 'loc_mean', 'sd.loc': 'loc_sd', 'wk': 'wk_mean', 'sd.wk': 'wk_sd', 'tod': 'tod_mean', 'sd.tod': 'tod_sd', 'seas': 'seas_mean', 'sd.seas': 'seas_sd'}\n",
    "for i in range(len(model_jax_bfgs.coeff_)):\n",
    "    name = model_jax_bfgs.coeff_names[i]\n",
    "    print(fmt.format(name[:13], \n",
    "                     model_jax_bfgs.coeff_[i], \n",
    "                     model_jax_lbfgs.coeff_[i], \n",
    "                     model_x.coeff_[i]))\n",
    "print(\"-\" * 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bcacd",
   "metadata": {},
   "source": [
    "# Predict\n",
    "jaxlogit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aadb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_jax \n",
    "config = ConfigData(\n",
    "    panels=panels_test,\n",
    "    n_draws=n_draws,\n",
    "    skip_std_errs=True,  # skip standard errors to speed up the example\n",
    "    batch_size=None,\n",
    "    optim_method=\"L-BFGS-B\",\n",
    ")\n",
    "config.init_coeff = init_coeff_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33951641",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_jj = model.predict(X_test, varnames, alts_test, ids_test, randvars, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64941385",
   "metadata": {},
   "source": [
    "xlogit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e13c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, prob_xx = model_x.predict(X_test, varnames, alts_test, ids_test, isvars=None, panels=panels_test, n_draws=n_draws, return_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed7228",
   "metadata": {},
   "source": [
    "Biogeme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {\n",
    "    j: MonteCarlo(models.logit(V, None, j))\n",
    "    for j in [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "simulate = {\n",
    "    f'Prob_alt{j}': P[j]\n",
    "    for j in [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "biogeme_sim = bio.BIOGEME(database_test, simulate)\n",
    "biogeme_sim.model_name = 'per_choice_probs'\n",
    "\n",
    "probs = biogeme_sim.simulate(results.get_beta_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20a479",
   "metadata": {},
   "source": [
    "Compute the brier score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:>9} {:>9} {:>9}\".format(\"Jaxlogit\", \"xlogit\", \"Biogeme\"))\n",
    "print(\"-\" * 31)\n",
    "fmt = \"{:9f} {:9f} {:9f}\"\n",
    "print(fmt.format(sklearn.metrics.brier_score_loss(np.reshape(y_test, (prob_jj.shape[0], -1)), prob_jj),\n",
    "                 sklearn.metrics.brier_score_loss(np.reshape(y_test, (prob_xx.shape[0], -1)), prob_xx),\n",
    "                 sklearn.metrics.brier_score_loss(df_wide_test['choice'], probs)))\n",
    "print(\"-\" * 31)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
