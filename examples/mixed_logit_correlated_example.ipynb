{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJHlxbR5kEe-"
      },
      "source": [
        "# Mixed Logit with correlations\n",
        "\n",
        "Using swissmetro data, comparing results to biogeme (Bierlaire, M. (2018). PandasBiogeme: a short introduction. EPFL (Transport and Mobility Laboratory, ENAC))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQbZt7CVh8f_",
        "outputId": "b823e80f-fd47-4dd1-8656-3fd0d6a1e26a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jax\n",
        "\n",
        "from jaxlogit.mixed_logit import MixedLogit, ConfigData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  64bit precision\n",
        "jax.config.update(\"jax_enable_x64\", True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP77ezqVfvRI"
      },
      "source": [
        "## Swissmetro Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOWB3Lffg5Qc"
      },
      "source": [
        "\n",
        "The swissmetro dataset contains stated-preferences for three alternative transportation modes that include car, train and a newly introduced mode: the swissmetro. This dataset is commonly used for estimation examples with the `Biogeme` and `PyLogit` packages. The dataset is available at http://transp-or.epfl.ch/data/swissmetro.dat and [Bierlaire et. al., (2001)](https://transp-or.epfl.ch/documents/proceedings/BierAxhaAbay01.pdf) provides a detailed discussion of the data as wells as its context and collection process. The explanatory variables in this example include the travel time (`TT`) and cost `CO` for each of the three alternative modes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4No84MAeFOM"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEzmVzYDdLS8"
      },
      "source": [
        "The dataset is imported to the Python environment using `pandas`. Then, two types of samples, ones with a trip purpose different to commute or business and ones with an unknown choice, are filtered out. The original dataset contains 10,729 records, but after filtering, 6,768 records remain for following analysis. Finally, a new column that uniquely identifies each sample is added to the dataframe and the `CHOICE` column, which originally contains a numerical coding of the choices, is mapped to a description that is consistent with the alternatives in the column names. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4jqERhnWhGCc",
        "outputId": "6bbdca2a-1670-4836-c0d5-d16915ee9597"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GROUP</th>\n",
              "      <th>SURVEY</th>\n",
              "      <th>SP</th>\n",
              "      <th>ID</th>\n",
              "      <th>PURPOSE</th>\n",
              "      <th>FIRST</th>\n",
              "      <th>TICKET</th>\n",
              "      <th>WHO</th>\n",
              "      <th>LUGGAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>...</th>\n",
              "      <th>TRAIN_CO</th>\n",
              "      <th>TRAIN_HE</th>\n",
              "      <th>SM_TT</th>\n",
              "      <th>SM_CO</th>\n",
              "      <th>SM_HE</th>\n",
              "      <th>SM_SEATS</th>\n",
              "      <th>CAR_TT</th>\n",
              "      <th>CAR_CO</th>\n",
              "      <th>CHOICE</th>\n",
              "      <th>custom_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>48</td>\n",
              "      <td>120</td>\n",
              "      <td>63</td>\n",
              "      <td>52</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>65</td>\n",
              "      <td>SM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>48</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>49</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>84</td>\n",
              "      <td>SM</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>48</td>\n",
              "      <td>60</td>\n",
              "      <td>67</td>\n",
              "      <td>58</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>52</td>\n",
              "      <td>SM</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>63</td>\n",
              "      <td>52</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>52</td>\n",
              "      <td>SM</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>60</td>\n",
              "      <td>63</td>\n",
              "      <td>42</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>84</td>\n",
              "      <td>SM</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8446</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>939</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>30</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>64</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>6763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8447</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>939</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>53</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>6764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8448</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>939</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>64</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>6765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8449</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>939</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>104</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>6766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8450</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>939</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>53</td>\n",
              "      <td>21</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>6767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6768 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      GROUP  SURVEY  SP   ID  PURPOSE  FIRST  TICKET  WHO  LUGGAGE  AGE  ...  \\\n",
              "0         2       0   1    1        1      0       1    1        0    3  ...   \n",
              "1         2       0   1    1        1      0       1    1        0    3  ...   \n",
              "2         2       0   1    1        1      0       1    1        0    3  ...   \n",
              "3         2       0   1    1        1      0       1    1        0    3  ...   \n",
              "4         2       0   1    1        1      0       1    1        0    3  ...   \n",
              "...     ...     ...  ..  ...      ...    ...     ...  ...      ...  ...  ...   \n",
              "8446      3       1   1  939        3      1       7    3        1    5  ...   \n",
              "8447      3       1   1  939        3      1       7    3        1    5  ...   \n",
              "8448      3       1   1  939        3      1       7    3        1    5  ...   \n",
              "8449      3       1   1  939        3      1       7    3        1    5  ...   \n",
              "8450      3       1   1  939        3      1       7    3        1    5  ...   \n",
              "\n",
              "      TRAIN_CO  TRAIN_HE  SM_TT  SM_CO  SM_HE  SM_SEATS  CAR_TT  CAR_CO  \\\n",
              "0           48       120     63     52     20         0     117      65   \n",
              "1           48        30     60     49     10         0     117      84   \n",
              "2           48        60     67     58     30         0     117      52   \n",
              "3           40        30     63     52     20         0      72      52   \n",
              "4           36        60     63     42     20         0      90      84   \n",
              "...        ...       ...    ...    ...    ...       ...     ...     ...   \n",
              "8446        13        30     50     17     30         0     130      64   \n",
              "8447        12        30     53     16     10         0      80      80   \n",
              "8448        16        60     50     16     20         0      80      64   \n",
              "8449        16        30     53     17     30         0      80     104   \n",
              "8450        13        60     53     21     30         0     100      80   \n",
              "\n",
              "      CHOICE  custom_id  \n",
              "0         SM          0  \n",
              "1         SM          1  \n",
              "2         SM          2  \n",
              "3         SM          3  \n",
              "4         SM          4  \n",
              "...      ...        ...  \n",
              "8446   TRAIN       6763  \n",
              "8447   TRAIN       6764  \n",
              "8448   TRAIN       6765  \n",
              "8449   TRAIN       6766  \n",
              "8450   TRAIN       6767  \n",
              "\n",
              "[6768 rows x 29 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_wide = pd.read_table(\"http://transp-or.epfl.ch/data/swissmetro.dat\", sep='\\t')\n",
        "\n",
        "# Keep only observations for commute and business purposes that contain known choices\n",
        "df_wide = df_wide[(df_wide['PURPOSE'].isin([1, 3]) & (df_wide['CHOICE'] != 0))]\n",
        "\n",
        "df_wide['custom_id'] = np.arange(len(df_wide))  # Add unique identifier\n",
        "df_wide['CHOICE'] = df_wide['CHOICE'].map({1: 'TRAIN', 2:'SM', 3: 'CAR'})\n",
        "df_wide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRMhgM2eIPz"
      },
      "source": [
        "### Reshape data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9OxW-yNhcal"
      },
      "source": [
        "The imported dataframe is in wide format, and it needs to be reshaped to long format for processing by `xlogit`, which offers the convenient `wide_to_long` utility for this reshaping process. The user needs to specify the column that uniquely identifies each sample, the names of the alternatives, the columns that vary across alternatives, and whether the alternative names are a prefix or suffix of the column names. Additionally, the user can specify a value (`empty_val`) to be used by default when an alternative is not available for a certain variable. Additional usage examples for the `wide_to_long` function are available in xlogit's documentation at https://xlogit.readthedocs.io/en/latest/notebooks/convert_data_wide_to_long.html. Also, details about the function parameters are available at the [API reference ](https://xlogit.readthedocs.io/en/latest/api/utils.html#xlogit.utils.wide_to_long)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1KM-BvFvhWed",
        "outputId": "33a6bacf-9674-4fec-eeca-90ab763a3308"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>custom_id</th>\n",
              "      <th>alt</th>\n",
              "      <th>TT</th>\n",
              "      <th>CO</th>\n",
              "      <th>HE</th>\n",
              "      <th>AV</th>\n",
              "      <th>SEATS</th>\n",
              "      <th>GROUP</th>\n",
              "      <th>SURVEY</th>\n",
              "      <th>SP</th>\n",
              "      <th>...</th>\n",
              "      <th>TICKET</th>\n",
              "      <th>WHO</th>\n",
              "      <th>LUGGAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>MALE</th>\n",
              "      <th>INCOME</th>\n",
              "      <th>GA</th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>DEST</th>\n",
              "      <th>CHOICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>112</td>\n",
              "      <td>48</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>SM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>SM</td>\n",
              "      <td>63</td>\n",
              "      <td>52</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>SM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>CAR</td>\n",
              "      <td>117</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>SM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>103</td>\n",
              "      <td>48</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>SM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>SM</td>\n",
              "      <td>60</td>\n",
              "      <td>49</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>SM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20299</th>\n",
              "      <td>6766</td>\n",
              "      <td>SM</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20300</th>\n",
              "      <td>6766</td>\n",
              "      <td>CAR</td>\n",
              "      <td>80</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20301</th>\n",
              "      <td>6767</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>108</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20302</th>\n",
              "      <td>6767</td>\n",
              "      <td>SM</td>\n",
              "      <td>53</td>\n",
              "      <td>21</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20303</th>\n",
              "      <td>6767</td>\n",
              "      <td>CAR</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20304 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       custom_id    alt   TT   CO   HE  AV  SEATS  GROUP  SURVEY  SP  ...  \\\n",
              "0              0  TRAIN  112   48  120   1      0      2       0   1  ...   \n",
              "1              0     SM   63   52   20   1      0      2       0   1  ...   \n",
              "2              0    CAR  117   65    0   1      0      2       0   1  ...   \n",
              "3              1  TRAIN  103   48   30   1      0      2       0   1  ...   \n",
              "4              1     SM   60   49   10   1      0      2       0   1  ...   \n",
              "...          ...    ...  ...  ...  ...  ..    ...    ...     ...  ..  ...   \n",
              "20299       6766     SM   53   17   30   1      0      3       1   1  ...   \n",
              "20300       6766    CAR   80  104    0   1      0      3       1   1  ...   \n",
              "20301       6767  TRAIN  108   13   60   1      0      3       1   1  ...   \n",
              "20302       6767     SM   53   21   30   1      0      3       1   1  ...   \n",
              "20303       6767    CAR  100   80    0   1      0      3       1   1  ...   \n",
              "\n",
              "       TICKET  WHO  LUGGAGE  AGE  MALE  INCOME  GA  ORIGIN  DEST  CHOICE  \n",
              "0           1    1        0    3     0       2   0       2     1      SM  \n",
              "1           1    1        0    3     0       2   0       2     1      SM  \n",
              "2           1    1        0    3     0       2   0       2     1      SM  \n",
              "3           1    1        0    3     0       2   0       2     1      SM  \n",
              "4           1    1        0    3     0       2   0       2     1      SM  \n",
              "...       ...  ...      ...  ...   ...     ...  ..     ...   ...     ...  \n",
              "20299       7    3        1    5     1       2   0       1     2   TRAIN  \n",
              "20300       7    3        1    5     1       2   0       1     2   TRAIN  \n",
              "20301       7    3        1    5     1       2   0       1     2   TRAIN  \n",
              "20302       7    3        1    5     1       2   0       1     2   TRAIN  \n",
              "20303       7    3        1    5     1       2   0       1     2   TRAIN  \n",
              "\n",
              "[20304 rows x 23 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jaxlogit.utils import wide_to_long\n",
        "\n",
        "df = wide_to_long(df_wide, id_col='custom_id', alt_name='alt', sep='_',\n",
        "                  alt_list=['TRAIN', 'SM', 'CAR'], empty_val=0,\n",
        "                  varying=['TT', 'CO', 'HE', 'AV', 'SEATS'], alt_is_prefix=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhLjuzaSeVjE"
      },
      "source": [
        "### Create model specification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgJP2WdQeXiY"
      },
      "source": [
        "Following the reshaping, users can create or update the dataset's columns in order to accommodate their model specification needs, if necessary. The code below shows how the columns `ASC_TRAIN` and `ASC_CAR` were created to incorporate alternative-specific constants in the model. In addition, the example illustrates an effective way of establishing variable interactions (e.g., trip costs for commuters with an annual pass) by updating existing columns conditional on values of other columns. Although apparently simple, column operations provide users with an intuitive and highly-flexible mechanism to incorporate model specification aspects, such as variable transformations, interactions, and alternative specific coefficients and constants. By operating the dataframe columns, any utility specification can be accommodated in `xlogit`. As shown in [this specification example](https://xlogit.readthedocs.io/en/latest/notebooks/multinomial_model.html#Create-model-specification), highly-flexible utility specifications can be modeled in `xlogit` by operating the dataframe columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MsSu2jqKeoz-"
      },
      "outputs": [],
      "source": [
        "df['ASC_TRAIN'] = np.ones(len(df))*(df['alt'] == 'TRAIN')\n",
        "df['ASC_CAR'] = np.ones(len(df))*(df['alt'] == 'CAR')\n",
        "df['TT'], df['CO'] = df['TT']/100, df['CO']/100  # Scale variables\n",
        "annual_pass = (df['GA'] == 1) & (df['alt'].isin(['TRAIN', 'SM']))\n",
        "df.loc[annual_pass, 'CO'] = 0  # Cost zero for pass holders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgjEi8QLexj6"
      },
      "source": [
        "### Estimate model parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzuSO2UBe99t"
      },
      "source": [
        "The `fit` method estimates the model by taking as input the data from the previous step along with additional specification criteria, such as the distribution of the random parameters (`randvars`), the number of random draws (`n_draws`), and the availability of alternatives for the choice situations (`avail`). We set the optimization method as `L-BFGS-B` as this is a robust routine that usually helps solve convergence issues.  Once the estimation routine is completed, the `summary` method can be used to display the estimation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dctkrAPBez4T",
        "outputId": "eaacd08d-fec7-4b8d-b0dd-757e4f3eac15"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "maximum supported dimension for an ndarray is currently 64, found 20304",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m varnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASC_CAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASC_TRAIN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MixedLogit()\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m ConfigData(\n\u001b[1;32m      5\u001b[0m     n_draws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, \n\u001b[0;32m----> 6\u001b[0m     avail\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      7\u001b[0m     panels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mndarray(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     11\u001b[0m     df[varnames],\n\u001b[1;32m     12\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCHOICE\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     config\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
            "\u001b[0;31mValueError\u001b[0m: maximum supported dimension for an ndarray is currently 64, found 20304"
          ]
        }
      ],
      "source": [
        "varnames=['ASC_CAR', 'ASC_TRAIN', 'CO', 'TT']\n",
        "model = MixedLogit()\n",
        "\n",
        "config = ConfigData(\n",
        "    n_draws=1500, \n",
        "    avail=(df['AV']),\n",
        "    panels=(df[\"ID\"]),\n",
        ")\n",
        "\n",
        "res = model.fit(\n",
        "    df[varnames],\n",
        "    df['CHOICE'],\n",
        "    varnames,\n",
        "    df['alt'],\n",
        "    df['custom_id'],\n",
        "    {'TT': 'n'},\n",
        "    config\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example of fixing parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we left this one out before, let's add it and assert parameters to 0\n",
        "df['ASC_SM'] = np.ones(len(df))*(df['alt'] == 'SM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-14 00:28:51,389 INFO jaxlogit.mixed_logit: Starting data preparation, including generation of 1500 random draws for each random variable and observation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-14 00:28:52,772 INFO jaxlogit.mixed_logit: Data contains 752 panels, using segment_sum for panel-wise log-likelihood.\n",
            "2025-07-14 00:28:52,773 INFO jaxlogit.mixed_logit: Shape of draws: (6768, 1, 1500), number of draws: 1500\n",
            "2025-07-14 00:28:52,774 INFO jaxlogit.mixed_logit: Shape of Xdf: (6768, 2, 4), shape of Xdr: (6768, 2, 1)\n",
            "2025-07-14 00:28:52,775 INFO jaxlogit.mixed_logit: Compiling log-likelihood function.\n",
            "2025-07-14 00:28:53,066 INFO jaxlogit.mixed_logit: Compilation finished, init neg_loglike = 6260.71, params= [(np.str_('ASC_CAR'), Array(0.1, dtype=float64)), (np.str_('ASC_TRAIN'), Array(0.1, dtype=float64)), (np.str_('ASC_SM'), Array(0., dtype=float64)), (np.str_('CO'), Array(0.1, dtype=float64)), (np.str_('TT'), Array(0.1, dtype=float64)), (np.str_('sd.TT'), Array(0.1, dtype=float64))]\n",
            "2025-07-14 00:28:53,067 INFO jaxlogit._optimize: Running minimization with method trust-region\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on this step: 6260.709404860119, Loss on the last accepted step: 0.0, Step size: 1.0\n",
            "Loss on this step: 205471.97895501574, Loss on the last accepted step: 6260.709404860119, Step size: 0.25\n",
            "Loss on this step: 123910.46308477379, Loss on the last accepted step: 6260.709404860119, Step size: 0.0625\n",
            "Loss on this step: 45412.46942728786, Loss on the last accepted step: 6260.709404860119, Step size: 0.015625\n",
            "Loss on this step: 13605.640755086313, Loss on the last accepted step: 6260.709404860119, Step size: 0.00390625\n",
            "Loss on this step: 5957.889047455692, Loss on the last accepted step: 6260.709404860119, Step size: 0.00390625\n",
            "Loss on this step: 4662.3115816798545, Loss on the last accepted step: 5957.889047455692, Step size: 0.00390625\n",
            "Loss on this step: 4515.0650097510315, Loss on the last accepted step: 4662.3115816798545, Step size: 0.00390625\n",
            "Loss on this step: 4418.413802576896, Loss on the last accepted step: 4515.0650097510315, Step size: 0.00390625\n",
            "Loss on this step: 4389.3841109539435, Loss on the last accepted step: 4418.413802576896, Step size: 0.00390625\n",
            "Loss on this step: 4377.098985190866, Loss on the last accepted step: 4389.3841109539435, Step size: 0.00390625\n",
            "Loss on this step: 4373.926044373106, Loss on the last accepted step: 4377.098985190866, Step size: 0.00390625\n",
            "Loss on this step: 4371.779481785484, Loss on the last accepted step: 4373.926044373106, Step size: 0.013671875\n",
            "Loss on this step: 4366.492515493317, Loss on the last accepted step: 4371.779481785484, Step size: 0.0478515625\n",
            "Loss on this step: 4360.161373732614, Loss on the last accepted step: 4366.492515493317, Step size: 0.0478515625\n",
            "Loss on this step: 4362.0337816061065, Loss on the last accepted step: 4360.161373732614, Step size: 0.011962890625\n",
            "Loss on this step: 4359.670984722539, Loss on the last accepted step: 4360.161373732614, Step size: 0.011962890625\n",
            "Loss on this step: 4359.520816715871, Loss on the last accepted step: 4359.670984722539, Step size: 0.011962890625\n",
            "Loss on this step: 4359.383365221588, Loss on the last accepted step: 4359.520816715871, Step size: 0.011962890625\n",
            "Loss on this step: 4359.34074402568, Loss on the last accepted step: 4359.383365221588, Step size: 0.011962890625\n",
            "Loss on this step: 4359.308053058354, Loss on the last accepted step: 4359.34074402568, Step size: 0.011962890625\n",
            "Loss on this step: 4359.2915105652755, Loss on the last accepted step: 4359.308053058354, Step size: 0.011962890625\n",
            "Loss on this step: 4359.276723927937, Loss on the last accepted step: 4359.2915105652755, Step size: 0.011962890625\n",
            "Loss on this step: 4359.2672176232345, Loss on the last accepted step: 4359.276723927937, Step size: 0.011962890625\n",
            "Loss on this step: 4359.259123856866, Loss on the last accepted step: 4359.2672176232345, Step size: 0.011962890625\n",
            "Loss on this step: 4359.252466426082, Loss on the last accepted step: 4359.259123856866, Step size: 0.011962890625\n",
            "Loss on this step: 4359.246705654759, Loss on the last accepted step: 4359.252466426082, Step size: 0.011962890625\n",
            "Loss on this step: 4359.242234524502, Loss on the last accepted step: 4359.246705654759, Step size: 0.011962890625\n",
            "Loss on this step: 4359.238538729163, Loss on the last accepted step: 4359.242234524502, Step size: 0.011962890625\n",
            "Loss on this step: 4359.235563628431, Loss on the last accepted step: 4359.238538729163, Step size: 0.011962890625\n",
            "Loss on this step: 4359.233015296204, Loss on the last accepted step: 4359.235563628431, Step size: 0.011962890625\n",
            "Loss on this step: 4359.2309310802575, Loss on the last accepted step: 4359.233015296204, Step size: 0.011962890625\n",
            "Loss on this step: 4359.229157559059, Loss on the last accepted step: 4359.2309310802575, Step size: 0.011962890625\n",
            "Loss on this step: 4359.227697662638, Loss on the last accepted step: 4359.229157559059, Step size: 0.011962890625\n",
            "Loss on this step: 4359.226439530055, Loss on the last accepted step: 4359.227697662638, Step size: 0.011962890625\n",
            "Loss on this step: 4359.2253903922765, Loss on the last accepted step: 4359.226439530055, Step size: 0.011962890625\n",
            "Loss on this step: 4359.224480539513, Loss on the last accepted step: 4359.2253903922765, Step size: 0.011962890625\n",
            "Loss on this step: 4359.223697755336, Loss on the last accepted step: 4359.224480539513, Step size: 0.011962890625\n",
            "Loss on this step: 4359.22301731122, Loss on the last accepted step: 4359.223697755336, Step size: 0.011962890625\n",
            "Loss on this step: 4359.2224251944235, Loss on the last accepted step: 4359.22301731122, Step size: 0.011962890625\n",
            "Loss on this step: 4359.221909899941, Loss on the last accepted step: 4359.2224251944235, Step size: 0.011962890625\n",
            "Loss on this step: 4359.221461800152, Loss on the last accepted step: 4359.221909899941, Step size: 0.011962890625\n",
            "Loss on this step: 4359.221073190443, Loss on the last accepted step: 4359.221461800152, Step size: 0.011962890625\n",
            "Loss on this step: 4359.220738093535, Loss on the last accepted step: 4359.221073190443, Step size: 0.011962890625\n",
            "Loss on this step: 4359.2204528006605, Loss on the last accepted step: 4359.220738093535, Step size: 0.011962890625\n",
            "Loss on this step: 4359.220216767542, Loss on the last accepted step: 4359.2204528006605, Step size: 0.011962890625\n",
            "Loss on this step: 4359.220034326254, Loss on the last accepted step: 4359.220216767542, Step size: 0.0418701171875\n",
            "Loss on this step: 4359.219642556484, Loss on the last accepted step: 4359.220034326254, Step size: 0.14654541015625\n",
            "Loss on this step: 4359.219276889609, Loss on the last accepted step: 4359.219642556484, Step size: 0.512908935546875\n",
            "Loss on this step: 4359.218748627566, Loss on the last accepted step: 4359.219276889609, Step size: 0.512908935546875\n",
            "Loss on this step: 4359.2330744781075, Loss on the last accepted step: 4359.218748627566, Step size: 0.12822723388671875\n",
            "Loss on this step: 4359.218710219622, Loss on the last accepted step: 4359.218748627566, Step size: 0.12822723388671875\n",
            "Loss on this step: 4359.224276517987, Loss on the last accepted step: 4359.218710219622, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.218475291209, Loss on the last accepted step: 4359.218710219622, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.218340696849, Loss on the last accepted step: 4359.218475291209, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.218265088024, Loss on the last accepted step: 4359.218340696849, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.218254357514, Loss on the last accepted step: 4359.218265088024, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.218233036162, Loss on the last accepted step: 4359.218254357514, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.2182316339, Loss on the last accepted step: 4359.218233036162, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.218231000705, Loss on the last accepted step: 4359.2182316339, Step size: 0.03205680847167969\n",
            "Loss on this step: 4359.2182308188285, Loss on the last accepted step: 4359.218231000705, Step size: 0.1121988296508789\n",
            "Loss on this step: 4359.218230376183, Loss on the last accepted step: 4359.2182308188285, Step size: 0.39269590377807617\n",
            "Loss on this step: 4359.21822929761, Loss on the last accepted step: 4359.218230376183, Step size: 0.39269590377807617\n",
            "Loss on this step: 4359.21822925663, Loss on the last accepted step: 4359.21822929761, Step size: 0.39269590377807617\n",
            "Loss on this step: 4359.218229275025, Loss on the last accepted step: 4359.21822925663, Step size: 0.09817397594451904\n",
            "Loss on this step: 4359.218229243382, Loss on the last accepted step: 4359.21822925663, Step size: 0.09817397594451904\n",
            "Loss on this step: 4359.21822924053, Loss on the last accepted step: 4359.218229243382, Step size: 0.09817397594451904\n",
            "Loss on this step: 4359.218229239383, Loss on the last accepted step: 4359.21822924053, Step size: 0.09817397594451904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-14 00:29:06,969 INFO jaxlogit.mixed_logit: Optimization finished, success = True, final loglike = -4359.22, final gradient max = 7.47e-05, norm = 6.75e-04.\n",
            "2025-07-14 00:29:06,970 INFO jaxlogit.mixed_logit: Calculating gradient of individual log-likelihood contributions\n",
            "2025-07-14 00:29:09,407 INFO jaxlogit.mixed_logit: Calculating H_inv\n",
            "2025-07-14 00:29:13,737 INFO jaxlogit._choice_model: Post fit processing\n",
            "2025-07-14 00:29:14,097 INFO jaxlogit._choice_model: Optimization terminated successfully.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Message: \n",
            "    Iterations: 60\n",
            "    Function evaluations: 68\n",
            "Estimation time= 22.7 seconds\n",
            "---------------------------------------------------------------------------\n",
            "Coefficient              Estimate      Std.Err.         z-val         P>|z|\n",
            "---------------------------------------------------------------------------\n",
            "ASC_CAR                 0.2831110     0.0560480     5.0512276       4.5e-07 ***\n",
            "ASC_TRAIN              -0.5722733     0.0794778    -7.2004140      6.65e-13 ***\n",
            "ASC_SM                  0.0000000     0.0000000           nan           nan    \n",
            "CO                     -1.6601666     0.0778870   -21.3150710      1.26e-97 ***\n",
            "TT                     -3.2289976     0.1749805   -18.4534737      3.16e-74 ***\n",
            "sd.TT                   3.6221628     0.1728452    20.9561137      1.58e-94 ***\n",
            "---------------------------------------------------------------------------\n",
            "Significance:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
            "\n",
            "Log-Likelihood= -4359.218\n",
            "AIC= 8728.436\n",
            "BIC= 8762.536\n"
          ]
        }
      ],
      "source": [
        "varnames=['ASC_CAR', 'ASC_TRAIN', 'ASC_SM', 'CO', 'TT']\n",
        "fixedvars = {'ASC_SM': 0.0}  # Fixing parameters\n",
        "model = MixedLogit()\n",
        "res = model.fit(\n",
        "    X=df[varnames],\n",
        "    y=df['CHOICE'],\n",
        "    varnames=varnames,\n",
        "    alts=df['alt'],\n",
        "    ids=df['custom_id'],\n",
        "    avail=df['AV'],\n",
        "    panels=df[\"ID\"],\n",
        "    randvars={'TT': 'n'},\n",
        "    n_draws=1500,\n",
        "    fixedvars=fixedvars\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error components with correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-14 00:33:09,262 INFO jaxlogit.mixed_logit: Starting data preparation, including generation of 1500 random draws for each random variable and observation.\n",
            "2025-07-14 00:33:10,084 INFO jaxlogit.mixed_logit: Data contains 752 panels, using segment_sum for panel-wise log-likelihood.\n",
            "2025-07-14 00:33:10,085 INFO jaxlogit.mixed_logit: Shape of draws: (6768, 3, 1500), number of draws: 1500\n",
            "2025-07-14 00:33:10,086 INFO jaxlogit.mixed_logit: Shape of Xdf: (6768, 2, 2), shape of Xdr: (6768, 2, 3)\n",
            "2025-07-14 00:33:10,088 INFO jaxlogit.mixed_logit: Compiling log-likelihood function.\n",
            "2025-07-14 00:33:10,695 INFO jaxlogit.mixed_logit: Compilation finished, init neg_loglike = 5613.90, params= [(np.str_('ASC_CAR'), Array(0.1, dtype=float64)), (np.str_('ASC_TRAIN'), Array(0.1, dtype=float64)), (np.str_('ASC_SM'), Array(0., dtype=float64)), (np.str_('CO'), Array(0.1, dtype=float64)), (np.str_('TT'), Array(0.1, dtype=float64)), (np.str_('sd.ASC_CAR'), Array(0., dtype=float64)), (np.str_('sd.ASC_TRAIN'), Array(1., dtype=float64)), (np.str_('sd.ASC_SM'), Array(0.1, dtype=float64)), (np.str_('chol.ASC_CAR.ASC_TRAIN'), Array(0., dtype=float64)), (np.str_('chol.ASC_CAR.ASC_SM'), Array(0., dtype=float64)), (np.str_('chol.ASC_TRAIN.ASC_SM'), Array(0.1, dtype=float64))]\n",
            "2025-07-14 00:33:10,696 INFO jaxlogit._optimize: Running minimization with method trust-region\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on this step: 5613.900938455273, Loss on the last accepted step: 0.0, Step size: 1.0\n",
            "Loss on this step: 173679.09013504253, Loss on the last accepted step: 5613.900938455273, Step size: 0.25\n",
            "Loss on this step: 88430.18929743508, Loss on the last accepted step: 5613.900938455273, Step size: 0.0625\n",
            "Loss on this step: 30602.666199833566, Loss on the last accepted step: 5613.900938455273, Step size: 0.015625\n",
            "Loss on this step: 9426.075036749258, Loss on the last accepted step: 5613.900938455273, Step size: 0.00390625\n",
            "Loss on this step: 4477.711460357415, Loss on the last accepted step: 5613.900938455273, Step size: 0.00390625\n",
            "Loss on this step: 4232.214319932492, Loss on the last accepted step: 4477.711460357415, Step size: 0.00390625\n",
            "Loss on this step: 4152.4597956549105, Loss on the last accepted step: 4232.214319932492, Step size: 0.00390625\n",
            "Loss on this step: 4136.318184406516, Loss on the last accepted step: 4152.4597956549105, Step size: 0.013671875\n",
            "Loss on this step: 4107.3625463782055, Loss on the last accepted step: 4136.318184406516, Step size: 0.013671875\n",
            "Loss on this step: 4091.7357964524062, Loss on the last accepted step: 4107.3625463782055, Step size: 0.013671875\n",
            "Loss on this step: 4088.386909477412, Loss on the last accepted step: 4091.7357964524062, Step size: 0.013671875\n",
            "Loss on this step: 4085.263819797661, Loss on the last accepted step: 4088.386909477412, Step size: 0.013671875\n",
            "Loss on this step: 4083.659819460593, Loss on the last accepted step: 4085.263819797661, Step size: 0.0478515625\n",
            "Loss on this step: 4081.0771649807266, Loss on the last accepted step: 4083.659819460593, Step size: 0.0478515625\n",
            "Loss on this step: 4071.66954801608, Loss on the last accepted step: 4081.0771649807266, Step size: 0.16748046875\n",
            "Loss on this step: 4195.520808979151, Loss on the last accepted step: 4071.66954801608, Step size: 0.0418701171875\n",
            "Loss on this step: 4082.1097228103545, Loss on the last accepted step: 4071.66954801608, Step size: 0.010467529296875\n",
            "Loss on this step: 4071.4374293081596, Loss on the last accepted step: 4071.66954801608, Step size: 0.010467529296875\n",
            "Loss on this step: 4070.8686879979477, Loss on the last accepted step: 4071.4374293081596, Step size: 0.010467529296875\n",
            "Loss on this step: 4070.7415084936056, Loss on the last accepted step: 4070.8686879979477, Step size: 0.010467529296875\n",
            "Loss on this step: 4070.6780338613635, Loss on the last accepted step: 4070.7415084936056, Step size: 0.010467529296875\n",
            "Loss on this step: 4070.6461282752693, Loss on the last accepted step: 4070.6780338613635, Step size: 0.010467529296875\n",
            "Loss on this step: 4070.626713359182, Loss on the last accepted step: 4070.6461282752693, Step size: 0.010467529296875\n",
            "Loss on this step: 4070.614648150626, Loss on the last accepted step: 4070.626713359182, Step size: 0.0366363525390625\n",
            "Loss on this step: 4070.5886433771598, Loss on the last accepted step: 4070.614648150626, Step size: 0.12822723388671875\n",
            "Loss on this step: 4070.5572056494293, Loss on the last accepted step: 4070.5886433771598, Step size: 0.12822723388671875\n",
            "Loss on this step: 4070.5766115601373, Loss on the last accepted step: 4070.5572056494293, Step size: 0.03205680847167969\n",
            "Loss on this step: 4070.557000116686, Loss on the last accepted step: 4070.5572056494293, Step size: 0.03205680847167969\n",
            "Loss on this step: 4070.5568389192995, Loss on the last accepted step: 4070.557000116686, Step size: 0.03205680847167969\n",
            "Loss on this step: 4070.5567417950915, Loss on the last accepted step: 4070.5568389192995, Step size: 0.1121988296508789\n",
            "Loss on this step: 4070.556654377333, Loss on the last accepted step: 4070.5567417950915, Step size: 0.1121988296508789\n",
            "Loss on this step: 4070.55667506802, Loss on the last accepted step: 4070.556654377333, Step size: 0.028049707412719727\n",
            "Loss on this step: 4070.556652658449, Loss on the last accepted step: 4070.556654377333, Step size: 0.028049707412719727\n",
            "Loss on this step: 4070.556652198438, Loss on the last accepted step: 4070.556652658449, Step size: 0.028049707412719727\n",
            "Loss on this step: 4070.556652057649, Loss on the last accepted step: 4070.556652198438, Step size: 0.028049707412719727\n",
            "Loss on this step: 4070.556652009143, Loss on the last accepted step: 4070.556652057649, Step size: 0.09817397594451904\n",
            "Loss on this step: 4070.556651905359, Loss on the last accepted step: 4070.556652009143, Step size: 0.34360891580581665\n",
            "Loss on this step: 4070.5566516646004, Loss on the last accepted step: 4070.556651905359, Step size: 1.2026312053203583\n",
            "Loss on this step: 4070.556651899012, Loss on the last accepted step: 4070.5566516646004, Step size: 0.30065780133008957\n",
            "Loss on this step: 4070.5566515868863, Loss on the last accepted step: 4070.5566516646004, Step size: 1.0523023046553135\n",
            "Loss on this step: 4070.5566516619856, Loss on the last accepted step: 4070.5566515868863, Step size: 0.2630755761638284\n",
            "Loss on this step: 4070.5566515814044, Loss on the last accepted step: 4070.5566515868863, Step size: 0.2630755761638284\n",
            "Loss on this step: 4070.556651614391, Loss on the last accepted step: 4070.5566515814044, Step size: 0.0657688940409571\n",
            "Loss on this step: 4070.556651573802, Loss on the last accepted step: 4070.5566515814044, Step size: 0.0657688940409571\n",
            "Loss on this step: 4070.55665157303, Loss on the last accepted step: 4070.556651573802, Step size: 0.0657688940409571\n",
            "Loss on this step: 4070.5566515717396, Loss on the last accepted step: 4070.55665157303, Step size: 0.0657688940409571\n",
            "Loss on this step: 4070.5566515714822, Loss on the last accepted step: 4070.5566515717396, Step size: 0.0657688940409571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-14 00:33:39,250 INFO jaxlogit.mixed_logit: Optimization finished, success = True, final loglike = -4070.56, final gradient max = 1.49e-04, norm = 1.98e-04.\n",
            "2025-07-14 00:33:39,251 INFO jaxlogit.mixed_logit: Calculating gradient of individual log-likelihood contributions\n",
            "2025-07-14 00:33:49,715 INFO jaxlogit.mixed_logit: Calculating H_inv\n",
            "2025-07-14 00:34:06,117 INFO jaxlogit._choice_model: Post fit processing\n",
            "2025-07-14 00:34:06,250 INFO jaxlogit._choice_model: Optimization terminated successfully.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Message: \n",
            "    Iterations: 37\n",
            "    Function evaluations: 48\n",
            "Estimation time= 57.0 seconds\n",
            "---------------------------------------------------------------------------\n",
            "Coefficient              Estimate      Std.Err.         z-val         P>|z|\n",
            "---------------------------------------------------------------------------\n",
            "ASC_CAR                -0.2273947     0.1253061    -1.8147135        0.0696 .  \n",
            "ASC_TRAIN              -1.1971285     0.1388613    -8.6210391      8.17e-18 ***\n",
            "ASC_SM                  0.0000000     0.0000000           nan           nan    \n",
            "CO                     -2.0499603     0.1085217   -18.8898662      1.33e-77 ***\n",
            "TT                     -2.1520675     0.1045618   -20.5817736      2.39e-91 ***\n",
            "sd.ASC_CAR              0.0000000     0.0000000           nan           nan    \n",
            "sd.ASC_TRAIN            1.0000000     0.0000000           inf             0 ***\n",
            "sd.ASC_SM               2.5200232     0.1346184    18.7197506      2.81e-76 ***\n",
            "chol.ASC_CAR.ASC_TR     0.0000000     0.0000000           nan           nan    \n",
            "chol.ASC_CAR.ASC_SM     0.0000000     0.0000000           nan           nan    \n",
            "chol.ASC_TRAIN.ASC_     0.7362153     0.1501450     4.9033635      9.64e-07 ***\n",
            "---------------------------------------------------------------------------\n",
            "Significance:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
            "\n",
            "Log-Likelihood= -4070.557\n",
            "AIC= 8153.113\n",
            "BIC= 8194.033\n"
          ]
        }
      ],
      "source": [
        "varnames=['ASC_CAR', 'ASC_TRAIN', 'ASC_SM', 'CO', 'TT']\n",
        "\n",
        "randvars={'ASC_CAR': 'n', 'ASC_TRAIN': 'n', 'ASC_SM': 'n'}\n",
        "fixedvars = {\n",
        "    'ASC_SM': 0.0, 'sd.ASC_TRAIN': 1.0, 'sd.ASC_CAR': 0.0,\n",
        "    'chol.ASC_CAR.ASC_TRAIN': 0.0, 'chol.ASC_CAR.ASC_SM': 0.0\n",
        "}  # Identification of error components, see J. Walker's PhD thesis (MIT 2001)\n",
        "config = DataConfig()\n",
        "model = MixedLogit()\n",
        "res = model.fit(\n",
        "    X=df[varnames],\n",
        "    y=df['CHOICE'],\n",
        "    varnames=varnames,\n",
        "    alts=df['alt'],\n",
        "    ids=df['custom_id'],\n",
        "    avail=df['AV'],\n",
        "    panels=df[\"ID\"],\n",
        "    randvars=randvars,\n",
        "    n_draws=1500,\n",
        "    fixedvars=fixedvars,\n",
        "    include_correlations=True,  # Enable correlation between random parameters\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mixed_logit_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.10.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
